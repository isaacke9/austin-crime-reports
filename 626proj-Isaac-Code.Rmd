---
title: "STAT 626 Project - Crime Reports in Austin"
author: "Isaac Ke"
date: "7/4/22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Data is from [linked phrase](https://data.austintexas.gov/Public-Safety/Crime-Reports/fdj4-gpfu)

# 10 Minute Presentation & 5-Page Report
6. Transform the Data to Stationarity using regression (follow Example 3.5 in the text
as much as possible); Explain differencing, log-transform,.... if used.

7. ACF and PACF Plots: Use correlogram and partial correlogram to formulate ARMA(p,
q) models for the "stationary" data. If in doubt, choose from AR models, these are
simple to estimate, interpret and predict.

8. Fit and Forecast: Estimate the model parameters using simple-minded methods like
the least squares, Yule-Walker estimates, etc.

9. Diagnostic: Check the residuals to see if they are white noise.

10. You may want to consult the first three chapters of the text for notation, terminologies
and ideas.

```{r}
library(data.table)
library(lubridate)
library(ggplot2)
library(dplyr)
library(data.table)
library(ggrepel)
library(tidyverse)
library(RColorBrewer)
library(astsa)
require(forecast)
# library(qmap)
# library(ggmap)
```

# Load Cleaned Dataset
```{r}
setwd("~/A&M_Year4/STAT 626/Project-626/R/data")
load("crime.RData")
# comment
```

# Data Wrangling (Dates) 
```{r}
# Proper formatting
colnames(crime) = make.names(colnames(crime))
crime = as.data.frame(crime)

# sample size & number features
n = dim(crime)[1]
p = dim(crime)[2]

# Nicely formatted dates, extract portions of dates as new columns
datetime = mdy_hms(crime$Report.Date.Time, tz = "UTC")
crime$ymd = datetime
crime$year = year(crime$ymd)
crime$month = month(crime$ymd)
crime$datetime = datetime
crime$date = as.Date(crime$datetime)
crime$month_year = as.numeric(paste(as.numeric(year(crime$ymd)), as.numeric(month(crime$ymd)), sep=""))

```


```{r}
# Subsample crime by individual years (easier computation)
crime2021 = filter(crime, year == 2021)
crime2022 = filter(crime, year == 2022)

crimepermonth = crime %>%
  group_by(month_year) %>%
  summarize(Freq=n()) %>%
  filter(row_number()!=1 & row_number()!=n() & row_number()!=n()-1) %>% # get rid of the endpoint days with 0 
  filter(row_number()>=1 & row_number()<174) # get rid of outlier dip (from 2-2003 to 3-2022)

crimeperday = crime %>% # from (1/1/2003 to 4/1/2022)
  group_by(date) %>%
  summarize(Freq=n()) %>%
  filter(row_number()!=1 & row_number()!=n() & row_number()!=n()-1) # get rid of the endpoint days with 0 

crimeperdaytheft = crime %>%
  filter(Category.Description=="Theft") %>%
  group_by(date) %>%
  summarize(Freq=n()) %>%
  filter(row_number()!=1 & row_number()!=n() & row_number()!=n()-1)

crimeperyear = crime %>%
  group_by(year) %>%
  summarize(Freq=n()) %>%
  filter(row_number()!=1 & row_number()!=n() & row_number()!=n()-1)

crimeperday2021 = crime2021 %>%
  group_by(date) %>%
  summarize(Freq=n()) %>%
  filter(row_number()!=1 & row_number()!=n() & row_number()!=n()-1)

############################
# Crime count per **** 
x = ts(crimepermonth)  # CHANGE
############################

ma = stats::filter(x[,2], sides = 2, filter = rep(1/12,12))

tsplot(x[,2], main="Police Reports in Austin", col=4, 
       ylab = "Number of Police Reports", 
       xlab = "Number of units since January 1, 2003")
lines(ma, type="l", lty=2, col = "red")
legend(5000, 525, legend=c("Data", "Moving Average"),
       col=c("blue", "red"), lty=1:1, cex=0.8)

```


## See crime per month (cycle within year)
```{r}
crimemonth = crime %>%
  group_by(month) %>%
  summarize(Freq=n()) %>%
  filter(row_number()!=1 & row_number()!=n() & row_number()!=n()-1) # get rid of the endpoint days with 0 

plot(crimemonth$month, crimemonth$Freq, 
     main = "Plot of Crime Count vs Month", 
     xlab = "Month",
     ylab = "Total Crime Count")
```


# Kernel Smoother to Estimate Trend
```{r}
tsplot(x[,2], col="blue",
       main = "Daily Crime Reports in Austin (Kernel Bandwidth=12)", ylab = "Total Number of Polics Reports")  
lines(ksmooth(time(x[,2]), x[,2], "normal", bandwidth=12), lwd=2, col="red")  

tsplot(x[,2], col="blue",
       main = "Daily Crime Reports in Austin (Kernel Bandwidth=30)", ylab = "Total Number of Polics Reports")  
lines(ksmooth(time(x[,2]), x[,2], "normal", bandwidth=30), lwd=2, col="red")  

```


# Transform to Stationarity 
```{r}
# Check for equal variance
n = length(x[,2])
cat("sample variance first half of TS:", sd(x[,2][1:n/2])^2, "\n")
cat("sample variance second half of TS:", sd(x[,2][((n/2)+1):n])^2)

# check normality
qqnorm(x[,2], main="", col=4)
qqline(x[,2], col=2, lwd=2)  

# Check ACF for trend
max.lag=165 # 7000, 220
acf1(x[,2], main = "ACF for Original TS", max.lag=max.lag)
acf1(x[,2], main = "PACF for Original TS", max.lag=max.lag, pacf=TRUE)
```



# First Order Difference 
```{r}
x_diff = diff(x[,2])
tsplot(x_diff, main="", ylab="", col=4, margin=0)  
mtext("First Order Difference", side=3, line=.5, cex=1.2, font=2, adj=0) 

# Check for equal variance
n = length(x_diff)
cat("sample variance first half of TS:", sd(x_diff[1:n/2])^2, "\n")
cat("sample variance second half of TS:", sd(x_diff[((n/2)+1):n])^2)

# check normality
qqnorm(x_diff, main="", col=4)
qqline(x_diff, col=2, lwd=2)  

max.lag=165 #7000, 220
acf1(x_diff, main = expression("Sample ACF Differenced"), max.lag=max.lag)
acf1(x_diff, main = expression("Sample PACF - Differenced"), max.lag=max.lag, pacf=TRUE)
```

```{r}
tsplot(x_diff, col="blue",
       main = "Daily Crime Reports in Austin (Kernel Bandwidth=3)", ylab = "Total Number of Polics Reports")  
lines(ksmooth(time(x_diff), x_diff, "normal", bandwidth=3), lwd=2, col="red")  
```

# ARMA Model Estimation
> choosing q and p in ARMA: https://towardsdatascience.com/identifying-ar-and-ma-terms-using-acf-and-pacf-plots-in-time-series-forecasting-ccb9fd073db8

The ACF and PACF plots should be considered together to define the process. For the AR process, we expect that the ACF plot will gradually decrease and simultaneously the PACF should have a sharp drop after p significant lags. To define a MA process, we expect the opposite from the ACF and PACF plots, meaning that: the ACF should show a sharp drop after a certain q number of lags while PACF should show a geometric or gradual decreasing trend. On the other hand, if both ACF and PACF plots demonstrate a gradual decreasing pattern, then the ARMA process should be considered for modeling.

```{r}
q=8 # AR order
d=0 # degree of differencing
p=0 # MA order
arma_fit = arima(x_diff, order=c(q,d,p))
summary(arma_fit)
plot(arma_fit$residuals, main = "ARMA Residuals", ylab = "Residuals")
checkresiduals(arma_fit)
```


# Forecast
```{r}
autoplot(forecast(arma_fit, level=95), ylab="Monthly Police Reports in Austin",
         xlab = "Time (months)")
```



